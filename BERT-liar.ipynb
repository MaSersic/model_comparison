{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Based on a notebook found here: https://www.kaggle.com/jeongwonkim10516/nlp-fake-news-with-bert-99-55-top1/notebook\n",
    "\n",
    "# Most basic stuff for EDA.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Libraries for text preprocessing.\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Loading pytorch packages.\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Setting some options for general use.\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set(font_scale=1.5)\n",
    "pd.options.display.max_columns = 250\n",
    "pd.options.display.max_rows = 250\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#Setting seeds for consistent results.\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Korisnik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Korisnik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Korisnik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Korisnik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.  \n",
    "    \n",
    "    device = torch.device('cuda')    \n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "    #device = torch.device('cpu')\n",
    "\n",
    "# If not...\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device('cpu')"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1060\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print('Using device:', device)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Using device: cuda\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# liar dataset\n",
    "train = pd.read_csv(r'.\\data\\liar_dataset\\train.tsv', sep=\"\\t\", header=None).values\n",
    "test = pd.read_csv(r'.\\data\\liar_dataset\\test.tsv', sep=\"\\t\", header=None).values\n",
    "\n",
    "# Changing labels from descriptors to 0/1\n",
    "# pants-fire, false, barely-true, half-true = 0\n",
    "# mostly-true, true = 1\n",
    "\n",
    "for i in range(0, len(train)):\n",
    "    if train[i, 1] in [\"mostly-true\", \"true\"]:\n",
    "        train[i, 1] = 1\n",
    "    else:\n",
    "        train[i, 1] = 0\n",
    "\n",
    "labels = train[:, 1].astype('int')     \n",
    "\n",
    "for i in range(0, len(test)):\n",
    "    if test[i, 1] in [\"mostly-true\", \"true\"]:\n",
    "        test[i, 1] = 1\n",
    "    else:\n",
    "        test[i, 1] = 0        \n",
    "\n",
    "test_labels = test[:, 1].astype('int')\n",
    "\n",
    "train = train[:, 2]\n",
    "test = test[:, 2]"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_map(sentence,labs='None'):\n",
    "    \n",
    "    \"\"\"A function for tokenize all of the sentences and map the tokens to their word IDs.\"\"\"\n",
    "    \n",
    "    global labels\n",
    "    \n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    \n",
    "    for text in sentence:\n",
    "        #   \"encode_plus\" will:\n",
    "        \n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        \n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            text,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            truncation='longest_first', # Activate and control truncation\n",
    "                            max_length = 84,           # Max length according to our text data.\n",
    "                            pad_to_max_length = True, # Pad & truncate all sentences.\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "\n",
    "        # Add the encoded sentence to the id list. \n",
    "        \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        \n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "    # Convert the lists into tensors.\n",
    "    \n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    if labs != 'None': # Setting this for using this definition for both train and test data so labels won't be a problem in our outputs.\n",
    "        labels = torch.tensor(labels)\n",
    "        return input_ids, attention_masks, labels\n",
    "    else:\n",
    "        return input_ids, attention_masks"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_ids, attention_masks, labels = tokenize_map(train, labels)\n",
    "test_input_ids, test_attention_masks = tokenize_map(test)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 80-20 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "8,192 training samples\n",
      "2,048 validation samples\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it here. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prediction_data = TensorDataset(test_input_ids, test_attention_masks)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased', # Use the 124-layer, 1024-hidden, 16-heads, 340M parameters BERT model with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification. You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the device which we set GPU in our case.\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Get all of the model's parameters as a list of tuples:\n",
    "\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print('{:<55} {:>12}'.format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print('{:<55} {:>12}'.format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print('{:<55} {:>12}'.format(p[0], str(tuple(p[1].size()))))"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch).\n",
    "\n",
    "# The 'W' stands for 'Weight Decay fix' probably...\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 6e-6, # args.learning_rate\n",
    "                  eps = 1e-8 # args.adam_epsilon\n",
    "                )"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "\n",
    "# We chose to run for 3, but we'll see later that this may be over-fitting the training data.\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs] (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    \"\"\"A function for calculating accuracy scores\"\"\"\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    return accuracy_score(labels_flat, pred_flat)\n",
    "\n",
    "def flat_f1(preds, labels):\n",
    "    \n",
    "    \"\"\"A function for calculating f1 scores\"\"\"\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    return f1_score(labels_flat, pred_flat)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def format_time(elapsed):    \n",
    "    \n",
    "    \"\"\"A function that takes a time in seconds and returns a string hh:mm:ss\"\"\"\n",
    "    \n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# This training code is based on the `run_glue.py` script here:\n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, validation accuracy, f1 score and timings.\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print('')\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes:\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    \n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    \n",
    "    # `dropout` and `batchnorm` layers behave differently during training vs. test ,\n",
    "    # source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 10 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device(gpu in our case) using the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        \n",
    "        b_input_ids = batch[0].to(device).to(torch.int64)\n",
    "        b_input_mask = batch[1].to(device).to(torch.int64)\n",
    "        b_labels = batch[2].to(device).to(torch.int64)\n",
    "        \n",
    "        # Always clear any previously calculated gradients before performing a backward pass. PyTorch doesn't do this automatically because accumulating the gradients is 'convenient while training RNNs'. \n",
    "        # Source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n",
    "        \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is down here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers BertForSequenceClassification.\n",
    "        \n",
    "        # It returns different numbers of parameters depending on what arguments given and what flags are set. For our useage here, it returns the loss (because we provided labels),\n",
    "        # And the 'logits' (the model outputs prior to activation.)\n",
    "        loss = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)[0]\n",
    "        logits = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)[1]\n",
    "        #print(loss)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end, \n",
    "        # `loss` is a tensor containing a single value; the `.item()` function just returns the Python value from the tensor.\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0 This is to help prevent the 'exploding gradients' problem.\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        \n",
    "        # The optimizer dictates the 'update rule'(How the parameters are modified based on their gradients, the learning rate, etc.)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    \n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print('')\n",
    "    print('  Average training loss: {0:.2f}'.format(avg_train_loss))\n",
    "    print('  Training epcoh took: {:}'.format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on our validation set.\n",
    "\n",
    "    print('')\n",
    "    print('Running Validation...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables:\n",
    "    \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    total_eval_f1 = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    \n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Training Time': training_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print('')\n",
    "print('Training complete!')\n",
    "\n",
    "print('Total training took {:} (h:mm:ss)'.format(format_time(time.time()-total_t0)))"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch    50  of  1,639.    Elapsed: 0:00:17.\n",
      "  Batch   100  of  1,639.    Elapsed: 0:00:28.\n",
      "  Batch   150  of  1,639.    Elapsed: 0:00:41.\n",
      "  Batch   200  of  1,639.    Elapsed: 0:00:54.\n",
      "  Batch   250  of  1,639.    Elapsed: 0:01:06.\n",
      "  Batch   300  of  1,639.    Elapsed: 0:01:18.\n",
      "  Batch   350  of  1,639.    Elapsed: 0:01:31.\n",
      "  Batch   400  of  1,639.    Elapsed: 0:01:43.\n",
      "  Batch   450  of  1,639.    Elapsed: 0:01:55.\n",
      "  Batch   500  of  1,639.    Elapsed: 0:02:08.\n",
      "  Batch   550  of  1,639.    Elapsed: 0:02:20.\n",
      "  Batch   600  of  1,639.    Elapsed: 0:02:32.\n",
      "  Batch   650  of  1,639.    Elapsed: 0:02:45.\n",
      "  Batch   700  of  1,639.    Elapsed: 0:02:57.\n",
      "  Batch   750  of  1,639.    Elapsed: 0:03:10.\n",
      "  Batch   800  of  1,639.    Elapsed: 0:03:22.\n",
      "  Batch   850  of  1,639.    Elapsed: 0:03:35.\n",
      "  Batch   900  of  1,639.    Elapsed: 0:03:47.\n",
      "  Batch   950  of  1,639.    Elapsed: 0:04:00.\n",
      "  Batch 1,000  of  1,639.    Elapsed: 0:04:12.\n",
      "  Batch 1,050  of  1,639.    Elapsed: 0:04:25.\n",
      "  Batch 1,100  of  1,639.    Elapsed: 0:04:37.\n",
      "  Batch 1,150  of  1,639.    Elapsed: 0:04:49.\n",
      "  Batch 1,200  of  1,639.    Elapsed: 0:05:02.\n",
      "  Batch 1,250  of  1,639.    Elapsed: 0:05:15.\n",
      "  Batch 1,300  of  1,639.    Elapsed: 0:05:27.\n",
      "  Batch 1,350  of  1,639.    Elapsed: 0:05:40.\n",
      "  Batch 1,400  of  1,639.    Elapsed: 0:05:53.\n",
      "  Batch 1,450  of  1,639.    Elapsed: 0:06:06.\n",
      "  Batch 1,500  of  1,639.    Elapsed: 0:06:18.\n",
      "  Batch 1,550  of  1,639.    Elapsed: 0:06:31.\n",
      "  Batch 1,600  of  1,639.    Elapsed: 0:06:43.\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:06:53\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch    50  of  1,639.    Elapsed: 0:00:12.\n",
      "  Batch   100  of  1,639.    Elapsed: 0:00:25.\n",
      "  Batch   150  of  1,639.    Elapsed: 0:00:38.\n",
      "  Batch   200  of  1,639.    Elapsed: 0:00:50.\n",
      "  Batch   250  of  1,639.    Elapsed: 0:01:03.\n",
      "  Batch   300  of  1,639.    Elapsed: 0:01:16.\n",
      "  Batch   350  of  1,639.    Elapsed: 0:01:29.\n",
      "  Batch   400  of  1,639.    Elapsed: 0:01:42.\n",
      "  Batch   450  of  1,639.    Elapsed: 0:01:54.\n",
      "  Batch   500  of  1,639.    Elapsed: 0:02:07.\n",
      "  Batch   550  of  1,639.    Elapsed: 0:02:20.\n",
      "  Batch   600  of  1,639.    Elapsed: 0:02:32.\n",
      "  Batch   650  of  1,639.    Elapsed: 0:02:45.\n",
      "  Batch   700  of  1,639.    Elapsed: 0:02:57.\n",
      "  Batch   750  of  1,639.    Elapsed: 0:03:10.\n",
      "  Batch   800  of  1,639.    Elapsed: 0:03:23.\n",
      "  Batch   850  of  1,639.    Elapsed: 0:03:35.\n",
      "  Batch   900  of  1,639.    Elapsed: 0:03:48.\n",
      "  Batch   950  of  1,639.    Elapsed: 0:04:03.\n",
      "  Batch 1,000  of  1,639.    Elapsed: 0:04:17.\n",
      "  Batch 1,050  of  1,639.    Elapsed: 0:04:30.\n",
      "  Batch 1,100  of  1,639.    Elapsed: 0:04:42.\n",
      "  Batch 1,150  of  1,639.    Elapsed: 0:04:54.\n",
      "  Batch 1,200  of  1,639.    Elapsed: 0:05:06.\n",
      "  Batch 1,250  of  1,639.    Elapsed: 0:05:19.\n",
      "  Batch 1,300  of  1,639.    Elapsed: 0:05:31.\n",
      "  Batch 1,350  of  1,639.    Elapsed: 0:05:43.\n",
      "  Batch 1,400  of  1,639.    Elapsed: 0:05:55.\n",
      "  Batch 1,450  of  1,639.    Elapsed: 0:06:07.\n",
      "  Batch 1,500  of  1,639.    Elapsed: 0:06:19.\n",
      "  Batch 1,550  of  1,639.    Elapsed: 0:06:32.\n",
      "  Batch 1,600  of  1,639.    Elapsed: 0:06:46.\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epcoh took: 0:06:56\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch    50  of  1,639.    Elapsed: 0:00:12.\n",
      "  Batch   100  of  1,639.    Elapsed: 0:00:25.\n",
      "  Batch   150  of  1,639.    Elapsed: 0:00:37.\n",
      "  Batch   200  of  1,639.    Elapsed: 0:00:49.\n",
      "  Batch   250  of  1,639.    Elapsed: 0:01:01.\n",
      "  Batch   300  of  1,639.    Elapsed: 0:01:14.\n",
      "  Batch   350  of  1,639.    Elapsed: 0:01:26.\n",
      "  Batch   400  of  1,639.    Elapsed: 0:01:38.\n",
      "  Batch   450  of  1,639.    Elapsed: 0:01:51.\n",
      "  Batch   500  of  1,639.    Elapsed: 0:02:03.\n",
      "  Batch   550  of  1,639.    Elapsed: 0:02:15.\n",
      "  Batch   600  of  1,639.    Elapsed: 0:02:28.\n",
      "  Batch   650  of  1,639.    Elapsed: 0:02:41.\n",
      "  Batch   700  of  1,639.    Elapsed: 0:02:53.\n",
      "  Batch   750  of  1,639.    Elapsed: 0:03:06.\n",
      "  Batch   800  of  1,639.    Elapsed: 0:03:18.\n",
      "  Batch   850  of  1,639.    Elapsed: 0:03:30.\n",
      "  Batch   900  of  1,639.    Elapsed: 0:03:43.\n",
      "  Batch   950  of  1,639.    Elapsed: 0:03:55.\n",
      "  Batch 1,000  of  1,639.    Elapsed: 0:04:07.\n",
      "  Batch 1,050  of  1,639.    Elapsed: 0:04:20.\n",
      "  Batch 1,100  of  1,639.    Elapsed: 0:04:32.\n",
      "  Batch 1,150  of  1,639.    Elapsed: 0:04:44.\n",
      "  Batch 1,200  of  1,639.    Elapsed: 0:04:57.\n",
      "  Batch 1,250  of  1,639.    Elapsed: 0:05:09.\n",
      "  Batch 1,300  of  1,639.    Elapsed: 0:05:22.\n",
      "  Batch 1,350  of  1,639.    Elapsed: 0:05:35.\n",
      "  Batch 1,400  of  1,639.    Elapsed: 0:05:47.\n",
      "  Batch 1,450  of  1,639.    Elapsed: 0:06:00.\n",
      "  Batch 1,500  of  1,639.    Elapsed: 0:06:12.\n",
      "  Batch 1,550  of  1,639.    Elapsed: 0:06:25.\n",
      "  Batch 1,600  of  1,639.    Elapsed: 0:06:38.\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:06:48\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:20:36 (h:mm:ss)\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Display floats with two decimal places.\n",
    "\n",
    "pd.set_option('precision', 3)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# Display the table.\n",
    "\n",
    "display(df_stats)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "       Training Loss Training Time\nepoch                             \n1              0.633       0:06:53\n2              0.593       0:06:56\n3              0.543       0:06:48",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Training Loss</th>\n      <th>Training Time</th>\n    </tr>\n    <tr>\n      <th>epoch</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.633</td>\n      <td>0:06:53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.593</td>\n      <td>0:06:56</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.543</td>\n      <td>0:06:48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Increase the plot size and font size:\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(12,8))\n",
    "\n",
    "# Plot the learning curve:\n",
    "\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label='Training')\n",
    "\n",
    "# Label the plot:\n",
    "\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks([1, 2])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz0AAAIjCAYAAAApw3UqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABhe0lEQVR4nO3dd3RUdfrH8c9MeiOEEFoCqUpJCEV6DyodReqq/EARWesKNmQXG+q6q4tlLaurgqKgAiIoEECkSEdERIGAJIGEEFoCaZS0+f2ByRISSpgkd3Lzfp3DOeSWmWfg8CQf7r3fx2Kz2WwCAAAAAJOyGl0AAAAAAFQmQg8AAAAAUyP0AAAAADA1Qg8AAAAAUyP0AAAAADA1Qg8AAAAAUyP0AADK9NRTT6lp06ZX/PXUU0/Z/V4LFixQ06ZNtWXLlnKdt2XLFjVt2lQLFiywu4by6N27t3r37l2l7wkAuHbORhcAAHBMo0aNUufOnYu//umnn/Tll19q1KhRuuGGG4q3N2nSxO73at++vV555RWFh4eX67zw8HC98soratu2rd01AADMi9ADAChTmzZt1KZNm+KvCwoK9OWXX6p169a69dZbK/S9GjdurMaNG5f7vLp161Z4LQAA8+H2NgAAAACmRugBANjtrbfeUsuWLfXdd9+pa9euatOmjebNmydJ2rVrlx5++GF16dJFkZGR6ty5sx577DEdOXKk+PyLn+kp+jouLk6PPfaY2rdvrzZt2ujBBx/UoUOHis+7+Jmeoq83bNig559/Xp07d1arVq00duxYxcXFlag5Ly9Pb7zxhnr16qVWrVpp9OjRiouLU4sWLfTWW29V2J/NypUr9ac//UnR0dFq166d7rvvvlK1HD58WA8//LC6deumli1basCAAfrggw9UWFhYfExGRoaeeuop9erVS1FRUbrppps0ffp0nTt3rsJqBQCz4vY2AECFyM/P19SpU3XPPfcoNzdXN9xwg/bu3as77rhDwcHBmjBhgjw8PLR9+3YtWrRIx44d06effnrZ17z//vsVHh6uSZMmKTk5WZ988omOHj2q+fPnX/a8qVOnql69enrggQeUkZGhDz/8UPfee69Wr14tZ+fz3/oef/xxLVu2TLfddptatmyp1atXa8yYMSWChr1mz56tadOmKSoqSo8++qiys7M1Z84c3X777frkk08UHR2tvLw8jR8/XmfPntVdd92lWrVqae3atfrXv/6lgoIC3XfffZKkiRMnavfu3RozZozq1aunn3/+Wf/973916tQpvfDCCxVWMwCYEaEHAFAhCgsLNXr0aE2YMKF427PPPiuLxaJZs2apdu3aks4vkJCXl6clS5bo1KlTxdvLEhUVVeKqy+nTp/XFF1/owIEDCgkJueR5/v7+mjNnjpycnCRJrq6umj59urZs2aKuXbtq27ZtWrZsme677z5NmjRJknTHHXfo4Ycf1nfffXftfwgXOHnypF599VVFR0dr9uzZcnV1lSQNGTJEgwYN0gsvvKB58+Zpz549io+P15tvvql+/fpJkkaMGKHx48crMTFRkpSWlqaNGzfqySef1D333FN8jM1mU3JycoXUCwBmxu1tAIAK061btxJfP/fcc1q1alWJYJOdnS03NzdJ50PM5fTv37/E182bN5cknThx4rLn9enTpzjwXHje8ePHJak42Nx9993Fx1gsFt17772Xfd3y2LRpk86cOaO77767OPBIUlBQkG655Rbt3LlTx44dU7169WSxWPT+++9r3bp1ys3NlcVi0UcffaR//vOfkiQfHx95enpqzpw5Wr58efGf28svv6yPP/64wmoGALPiSg8AoML4+/uX+NpisejkyZN6//33tXfvXiUlJenw4cOy2WySdMVbyfz8/Ep8XRQeCgoKLntenTp1yjyv6P0OHjyo2rVrl7rKFBYWdtnXLY+iZ4/Kes2ipbkPHz6s1q1b64knntBrr72m8ePHy9PTU507d9aAAQPUv39/OTk5ydXVVdOmTdPTTz+tv/zlL3J1dVWHDh3Up08fDRkypDhEAgDKRugBAFQYq7XkDQRr1qzRAw88oHr16qlTp07q0aOHoqKitH79er3//vvlfr1rreNieXl5cnFxKbW9qsJDUegrquGee+7RoEGD9N1332nt2rXasGGDvv/+ey1cuFAffvihJGnw4MHq3r27Vq5cqbVr12rjxo1av3695syZo3nz5pW4mgQAKInb2wAAleaFF15QcHCwli5dqn/84x8aN26cOnTooJMnTxpaV+PGjZWWlqbs7OwS2w8cOFBh7xEYGChJSkhIKLWvaFuDBg106tQpbd68WX5+fho9erQ++OADbdq0SX379tW6deu0d+9e5eTkaNu2bbJYLBo+fLjeeustbdq0SWPGjFFcXJzWr19fYXUDgBkRegAAlebUqVNq1KiRPD09i7elpqZqxYoVkq58m1plufnmm1VYWKg5c+aU2D579uwKe48uXbrIzc1NM2fOVG5ubvH2I0eO6Ntvv1V0dLT8/f21YcMGjR07VqtWrSo+xtPTU9dff70kycnJSb///rvuvPPOEqvWubq6qkWLFsXHAAAujdvbAACVpkePHlq6dKmeeeYZtWzZUocOHdLcuXN15swZSVJOTo4hdXXt2lUxMTGaPn26EhMT1bJlS23cuFHr1q2TdP5ZpCs5efKknnnmmTL3PfDAA2rQoIEeffRRvfzyy7r99ts1ePBg5eTk6PPPP1dhYaGmTp0qSYqJiVFoaKj+9re/adeuXWrSpIkSEhI0e/ZsderUSREREbLZbGrXrp1ef/11paamqmnTpkpNTdVnn32msLAwde7cueL+cADAhAg9AIBK89xzz8nT01OrVq3SokWL1KBBAw0ZMkQ333yzbr/9dm3evLn4akVVe/311/X6669ryZIlWrx4sdq0aaPXXntNDzzwwFU9H3P69Gl9+eWXZe67/fbb1aBBA911112qV6+eZsyYoddee00eHh7q0KGDHnroITVt2lTS+as6M2bM0L///W99++23OnHihAICAnTHHXfooYceknQ+hL3zzjt6++23tXr1an355Zfy9fVVnz599Mgjj/A8DwBcgcVW9DQlAAA1RFZWllxdXUstXPDbb79p2LBheumllzR8+HCDqgMAVDSe6QEA1DgrVqxQ69attX379hLblyxZIkmKjo42oiwAQCXhSg8AoMZJT09Xv3795OHhoTvvvFO1a9fWjh07tGDBAg0ePFivvvqq0SUCACoQoQcAUCPFx8frrbfe0rZt25SZmanAwEDddtttuueee1gNDQBMhtADAAAAwNR4pgcAAACAqRF6AAAAAJgac3qu4OTJHBUWGnsHoL+/t9LSsg2tAQDMgp4KAOZjtVrk5+d1yf2EnisoLLQZHnqK6gAAVAx6KgDULNzeBgAAAMDUCD0AAAAATI3QAwAAAMDUCD0AAAAATI3QAwAAAMDUWL0NAAAApnLmTI6ys0+poCDf6FJQAZycnOXtXVseHpdekvpKCD0AAAAwjTNncpSVdVK1awfIxcVVFovF6JJgB5vNpry8XJ06dVySrjn4cHsbAAAATCM7+5Rq1w6Qq6sbgccELBaLXF3dVLt2gLKzT13z6xB6AAAAYBoFBflycXE1ugxUMBcXV7tuVyT0AAAAwFS4wmM+9v6dEnoAAAAAmBqhBwAAAICpsXobAAAA4MBeeuk5xcYuvuwxrVu31dtv//eaXv+jj97XrFkztHbtlko9x0iEHgAAAMCB3XXXeN1667Dir1977R9ycnLSI488UbzNy+vaZ9gMHjxEnTp1rfRzjEToAQAAABxYYGCQAgODir/29PSSk5OzoqJaVsjr16tXX/Xq1a/0c4xE6HFgm3Yd0YK18UrPPKc6tdw0tGe4Okc2MLosAACAGqXoZ7K0zHPyd9CfyZYu/Vb/+tfL+stfHtNHH70vFxcXvfXW+2rQoKHmzJmlFStilZKSIqvVouuua6p7771fbdu2k1T6VrWHHpqgJk2C1bBhI3399XydOnVSTZs20yOPPK5mzVpc8zmS9MMPazRjxn+VlHRQQUFBevjhSXr88Uc0efJUDRgwuNL+fAg9DmrTriP6JDZOufmFkqS0zHP6JDZOkhzuHxkAAIBZVaefyfLy8jRnziz99a/P6NSpUwoMDNJbb72mb775Wvfd97DCwsJ1/PhxffzxB3rmmac0f/5iubu7l/laq1Z9p5CQME2a9IQKC2165503NHXqZM2du0hWa9lroV3pnB9/3KKpU59UTMyNuu++h/T773v1t79NVkFBQWX+sUgi9DisBWvji/9xFcnNL9SCtfEO9w8MAADA0W34NVXrd6aW+7z4wxnKL7CV2JabX6iZS/fohx2Hy/163aIbqmvLhuU+72rYbDbdddd4de7crXjbiRPH9ec/P6hhw0YWb3Nzc9Xf/vakEhPj1bx5ZJmvVVBQqNdee0uenuefFTp9OkcvvfSc4uP367rrrr+mcz7++EM1bdpMzz//siSpU6cuslqt+s9/3qqQz385hB4HlZZ5rlzbAQAAUPEuDjxX2m60sLCIEl8XBYyTJ08qKemgDh1K0oYN6ySdvzJ0KeHhEcXhRVLx8ztnz565pnNyc3P12287NX78/SXOufHGPoSemsy/lluZAcfJatGO/SfUKtyfacMAAABXqWvLa7vC8sS7G8r8mcy/lpsm39m2IkqrUHXq1CnxdVzcbk2f/g/t2bNb7u7uCg0NU/365+8asl0mt7m5lbztrejnzsLCS590uXMyMzNVUFAgP7/aF9Xrf9nPU1EYTuqghvYMl6tzyb8eZyeLvNyd9e/5O/Xq5z8rMTXToOoAAABqhrJ+JnN1tmpoz3CDKrp6OTnZeuyxh+Xp6a1PP52rFSt+0AcfzNLAgbdUeS1+fn5ydnbWyZMnS2w/eTK9St6f0OOgOkc20Nj+zeRfy00Wnf/fhLsHNNe/Huyq0X2uV8qJHL3wyTa9/80uHT916cuMAAAAuHYX/kwmnf+ZbGz/ZtXiGeuDBw8oIyNDo0bdodDQsOIFCDZv3ihJstkKL3d6hXJyclJUVLTWrVtbYvu6dWuq5P25vc2BdY5soM6RDRQQ4KPjx7OKt/duG6TOkQ0Uu+WgVmxN1k97j6l32yAN6hIibw8XAysGAAAwn6KfyaqbJk1C5OXlpY8//lAWi2S1OmnNmlVasmSRJOnMmar9j/Nx4ybokUfu1/PPT1W/fgN14ECCPvrov5JU6Y9tcKWnmvJwc9bQHuF6+c+d1Smygb77MVlPvbdJy7YkKS+/8pf9AwAAgGPz9vbWyy9PV2FhoaZOnawXX3xWR48e0dtv/1eenl7auXNHldbTtm07Pf/8y/r997166qlHtXTpYv3lL5MkSZ6enpX63hab7XKPMCEtLfuyD2xVhYuv9JTl0LFszVsTr18T0uRfy11De4apY4v6srLYAQCUcDU9FUD1deTIQTVoEGx0GSjD+vVrVb9+wxJLXm/atF5PPDFRH3/8uSIirrvs+Zf7u7VaLfL3977kudzeZhJB9bw1aWQr7T6Qrrmr9+uDb3drxdZkjYwJV/OQOld+AQAAAKASbdq0QevWrdX99z+sRo0Cdfhwij788D21aXPDFQOPvbjScwXV5UrPhQptNm3ZdVQLfohXWuY5RYf7a0SvcAUGXDr9AkBNwZUewNy40uO4zp49q/fee1vr1q1Renqa/PzqqEePGE2YcH+J+T6XYs+VHkLPFVTH0FMkL79AK386pMUbD+psbr66tWyoId3D5OfjVglVAkD1QOgBzI3QY17c3oYyuTg7qX/HYHWPbqTFGw/o+58Oacueo+rbvon6dWwiDzf++gEAAGB+/NRbA3h7uOhPN16n3jcEacHaeH278YDW7kjRrd1C1b1VIzk7sYgfAAAAzIufdmuQerU9dN+tUZo6pp0a+Hvp0xX79PRHW7V933FxlyMAADALfq4xH3v/Tgk9NVBYo1qafEcb/WVYtKwW6e0Fv+ofs7crPiXD6NIAAADs4uTkrLy8XKPLQAXLy8uVk9O136TGQgZXUJ0XMrgaBYWFWvdLqhauT1RmTq7aNQ3QsF7hqu9XuQOiAMAoLGQAmNuZMznKyjqp2rUD5OLiKgszC6s1m82mvLxcnTp1XD4+fvLwKHuVN1Zvs5PZQ0+Rs7n5WrYlScu2JqmgwKaYNoEa3DVEPp6ulfq+AFDVCD2A+Z05k6Ps7FMqKMg3uhRUACcnZ3l7175k4JEIPXarKaGnyKnsc1q0PlE//HJY7q5OGtApWDe3ayxXF6cqeX8AqGyEHgAwH0KPnWpa6Cly+ESO5q+J1479J+Tn46ahPcLUObKBrFYuEQOo3gg9AGA+hB471dTQU2Rv0knNXb1fialZalzPWyNiwhUV6m9ILQBQEQg9AGA+hB471fTQI0mFNpt+3HNMX62N14mMs4oMraMRvcLVpL6PYTUBwLUyuqcCACoeocdOhJ7/ycsv1Orth/TtxgM6fTZfXaIa6LYeYapTy93o0gDgqjlKTwUAVBxCj50IPaXlnM3Tkk0HtXLbIVks0s3tGmtAp2B5ul/72ukAUFUcracCAOxH6LEToefSTmSc0YIfErR511F5e7hocNcQxbQJlLMTM28BOC5H7akAgGtH6LEToefKDh7J0tzV+7Xn4EnV8/PQ8J7huqFpAMPAADgkR++pAIDyI/TYidBzdWw2m35NSNe8NfuVcjxH4Y1qaWTvCF0XVNvo0gCghOrQUwEA5UPosROhp3wKC23a8Guqvl6XoFPZuWp7fYCG9QxTQ/9LT9AFgKpUnXoqAODqEHrsROi5NudyC7RiW7KWbj6ovLxC9WzdSLd0C5Wvl6vRpQGo4apjTwUAXB6hx06EHvtk5uRq0YZErf35sFxcrBrQsYn6tG8iN1cno0sDUENV554KACgbocdOhJ6KkZqWo6/WJmj7vuOq7e2qId3D1K1lQ1mtLHYAoGqZoacCAEoi9NiJ0FOx9iWf0rzV+xV/OFOBdb00IiZcLcP8WekNQJUxU08FAJxH6LEToafi2Ww2/bT3uOavjdexk2fUPNhPI2MiFNzAx+jSANQAZuupAABCj90IPZUnv6BQa35O0TcbDij7TJ46RdbX0B5hquvrYXRpAEzMrD0VAGoyQo+dCD2V7/TZfMVuOagVPybLZrPpphsaa2CXYHm5uxhdGgATMntPBYCaiNBjJ0JP1UnPPKuv1yVo469H5OnurEFdQtS7bZBcnK1GlwbARGpKTwWAmoTQYydCT9VLOpql+Wvi9Vtiuur6umtozzB1aF5fVhY7AFABalpPBYCagNBjJ0KPcXYlpmvu6v1KPpatkAY+GtU7Qk2b+BldFoBqrqb2VAAwM0KPnQg9xiostGnTriNa8EOCTmadU6twfw2PiVBgXS+jSwNQTdXkngoAZkXosROhxzHk5hXou23JWrr5oM7mFqh7dCMN6R6q2t5uRpcGoJqhpwKA+RB67ETocSxZp3P17cYDWr09Rc5OVvXt0Fj9OjaRu6uz0aUBqCboqQBgPoQeOxF6HNOxk6c1f22CtsUdUy0vVw3pFqrurRrKycpKbwAuj54KAOZD6LETocexxR/O0NxV+/X7oQw19PfU8F7hah1RVxZWegNwCfRUADAfQo+dCD2Oz2azacfvJzRvTbyOpJ/W9Y1ra2RMhMIa1TK6NAAOiJ4KAOZD6LEToaf6yC8o1LpfDmvR+kRlns5Th+b1NLRnuOrV9jC6NAAOhJ4KAOZD6LEToaf6OXMuX8u2JGn5j0kqKLCpd9sgDe4aIm8PF6NLA+AA6KkAYD6EHjsReqqvk1nntGh9gtbtTJW7q7MGdQ7WTe2C5OLsZHRpAAxETwUA8yH02InQU/0dOp6t+WvitTM+Tf613HRbjzB1imwgK4sdADUSPRUAzIfQYydCj3nsOXhSc1ft18GjWWpS31sjYiIUGVLH6LIAVDF6KgCYD6HHToQecym02bR191F9tTZBaZlnFRVWRyN6RahxvUv/IwFgLvRUADAfQo+dCD3mlJdfoO9/StHijQd05ly+urZsqNt6hMnPx83o0gBUMnoqAJgPocdOhB5zyz6TpyWbDuj7nw7JarHo5vaNNaBTsDzcnI0uDUAloacCgPkQeuxE6KkZjp86owU/JGjL7qPy8XTRLV1D1bN1Izk7WY0uDUAFo6cCgPkQeuxE6KlZElMzNW/1fsUlnVJ9Pw8N7xWuttcHyMJKb4Bp0FMBwHwIPXYi9NQ8NptNO+PTNG9NvA6fyFFEoK9GxkQoIsjX6NIAVAB6KgCYD6HHToSemqugsFAbfj2ir9clKCM7Vzc0DdDwnuGqX8fT6NIA2IGeCgDmQ+ixE6EH53ILtHxrkmK3JCm/oFC9WgdqcLcQ1fJ0Nbo0ANeAngoA5kPosROhB0UycnK1aH2ifthxWK4uVg3oFKyb2zeWm4uT0aUBKAd6KgCYz5VCj+FLUy1evFgDBw5UdHS0+vfvr4ULF172+MLCQv3nP//RjTfeqOjoaA0ePFhLliwpcUx2drb++c9/6qabblLr1q01ePBgzZkzR+Q72MPXy1Vj+jbVC+M7qHmwnxb8kKC//nez1u08bHgwBgAAwKUZOowkNjZWjz/+uMaMGaPu3btr5cqVmjx5stzd3dWvX78yz/n73/+uL7/8Uo8++qiaNWumJUuW6LHHHpO3t7d69uwpSZo0aZJ27typv/zlLwoLC9PGjRv1wgsvKCsrS3/+85+r8iPChBr6e+nhYdHam3RSc1fHa+bSOH33Y7JGxEQoKrQOK70BAAA4GENvb7v55psVFRWl119/vXjbxIkTtXfvXsXGxpY6PikpSX379tW0adM0YsSI4u2jR49Ws2bNNHXqVO3Zs0dDhgzRG2+8of79+xcf8+yzz2rJkiXatm1buWrk9jZcjs1m049xx/TV2ngdP3VWLUL8NDImQk3q+xhdGoBLoKcCgPlc6fY2w670JCcnKykpSY8++miJ7X379lVsbKySk5PVuHHjEvtWrlwpd3d3DRkypMT2zz77rPj3NptNo0aNUufOnUscExYWpqysLJ08eVJ+fn4V+2FQY1ksFnVoXl9trgvQmp9T9M2GRD0/80d1imygoT3C5O/rbnSJAAAANZ5hz/QkJCRIkkJDQ0tsDw4OliQlJiaWOmfv3r0KDQ3Vxo0bdcstt6hFixbq06ePli5dWnxMixYtNG3aNNWuXbvEuStXrlRAQECp7UBFcHG26ub2jfXP+zqrX6cm+jHumKb8d7Pmrd6v02fzjC4PAACgRjMs9GRlnb+1wNu75GUoLy8vSecXI7hYenq6UlNT9de//lWjR4/Whx9+qMjISE2aNEmbN2++5Ht98skn2rp1q+69916et0Cl8nR30YheEXp5Qid1aF5Py7YkafJ7m7Tix2TlFxQaXR4AAECNZNjtbUWPEl0cQoq2W62l81heXp7S09P13nvvKSYmRpLUuXNnJSQk6O2331anTp1KnfPZZ5/p5ZdfVv/+/TVmzJhy13m5ewOrUkAAz4hUJwEBPpoSEaD4Q6f08eLd+uL737VmR4rG9G+hbq0bEb4Bg9FTAaBmMSz0+Pic/4Zz8RWdnJycEvsv5OXlJScnJ3Xt2rV4m8ViUZcuXTR//vwSxxYWFurVV1/VjBkzNGjQIP3zn/+8ph80WcgA9qjl5qSHh0ZpV2K65q7er1c+26Z539fSqN4Rur5xbaPLA2okeioAmI/DLmRQ9CxPUlKSmjZtWrz94MGDJfZfKDg4WIWFhcrPz5erq2vx9ry8vBKBJi8vT4899piWL1+ucePG6cknn+R/1mEYi8WiqDB/tQipow2/pWrhukT9Y/Z2tY6oqxEx4Wro72V0iQAAAKZm2DM9wcHBCgoK0rJly0psX7FihUJCQtSoUaNS53Tv3l02m63Ectb5+flat26dbrjhhuJtf/3rX7VixQpNmTJFkydPJvDAIVitFnWPbqS/T+ikoT3CFJd0Uk9/uFWzlu9VRvY5o8sDAAAwLUOHkz744IOaMmWKfH191atXL61atUqxsbHFc3vS09OVlJSkiIgIeXt7q3PnzurZs6defPFFnT59WiEhIZozZ45SUlI0ffp0SdKaNWv0zTffqHfv3mrdurV27NhR4j1btGhR4ioRUNXcXJw0qEuIerRupG/XH9CaHSna9NsR9e/YRH07NJGbq5PRJQIAAJiKocNJJemLL77QjBkzlJqaqsaNG2vChAnFc3gWLFigKVOmaNasWerYsaMk6ezZs3rzzTe1ePFiZWRkqEWLFnr00UfVoUMHSdKUKVO0YMGCS77f2rVr1aBBg6uuj2d6UNmOpp/W/LXx+mnvcfl6uWpI91B1i24opzIW8wBgP3oqAJjPlZ7pMTz0ODpCD6rK/pQMzV21X/tTMtSorpeG9wpXq3B/bs8EKhg9FQDMh9BjJ0IPqpLNZtP2fcc1f028jp48o2ZNamtETIRCG9YyujTANOipAGA+hB47EXpghPyCQq3dcVjfbEhU1uk8dWxRX0N7hCmgtofRpQHVHj0VAMyH0GMnQg+MdOZcvmK3HNSKrckqtNnUu22QBnUJkbeHi9GlAdUWPRUAzIfQYydCDxxBeuZZLVyfqA07U+Xh5qxBXUJ04w2BcnFmpTegvOipAGA+hB47EXrgSA4dy9bcNfv1W0K6/Gu5a1jPMHVoUV9WFjsArho9FQDMh9BjJ0IPHNGuA+mat3q/ko5mK7iBj0bGRKh5sJ/RZQHVAj0VAMyH0GMnQg8cVaHNpi27jmrBD/FKyzyn6HB/jegVrsCAS/+DB0BPBQAzIvTYidADR5eXX6CVPx3S4o0HdTY3X91aNtSQ7mHy83EzujTAIdFTAcB8CD12IvSgusg+k6dvNxzQqu2H5ORkUd/2TdSvYxN5uDkbXRrgUOipAGA+hB47EXpQ3Rw7dUYL1sZr655jquXpolu7hap7q0ZydrIaXRrgEOipAGA+hB47EXpQXSUcztTcVb9r36EMNajjqeG9wtXmurqysNIbajh6KgCYD6HHToQeVGc2m0079p/Q/DXxSk07reuCfDUyJkLhgb5GlwYYhp4KAOZD6LEToQdmUFBYqHW/pGrh+kRl5uSqXbN6GtYzTPX9PI0uDahy9FQAMB9Cj50IPTCTs7n5WrYlScu2JqmgwKaYNoEa3DVEPp6uRpcGVBl6KgCYD6HHToQemNGp7HNatD5RP/xyWO6uThrQKVg3t2ssVxcno0sDKh09FQDMh9BjJ0IPzCzlRI6+WhOvHftPyM/HTUN7hKlzZANZrSx2APOipwKA+RB67EToQU0Qd/Ck5q7erwNHstS4nrdGxkQoMrSO0WUBlYKeCgDmQ+ixE6EHNUWhzaYf9xzTV2vjdSLjrCJD62hEr3A1qe9jdGlAhaKnAoD5EHrsROhBTZOXX6hV2w9p8cYDOn02X12iGui2HmGqU8vd6NKACkFPBQDzIfTYidCDmirnbJ6WbDyolT8ly2KxqE/7xurfMVie7s5GlwbYhZ4KAOZD6LEToQc13YlTZ7RgXYI27zoqbw8XDe4aopg2gXJ2shpdGnBN6KkAYD6EHjsReoDzDh7J0tzV+7Xn4EnV8/PQ8J7huqFpgCwWVnpD9UJPBQDzIfTYidAD/I/NZtOvCemat2a/Uo7nKLxRLY3sHaHrgmobXRpw1eipAGA+hB47EXqA0goLbVr/a6q+XpegjOxctb0+QMN6hqmhv5fRpQFXRE8FAPMh9NiJ0ANc2rncAq34MUlLtyQpL69QPds00q1dQ1XLy9Xo0oBLoqcCgPkQeuxE6AGuLCMnV99sSNTanw/LxcWqAR2bqE+HJnJzcTK6NKAUeioAmA+hx06EHuDqpablaP6aeP38+wnV9nbVkO5h6tayoaxWFjuA46CnAoD5EHrsROgBym9f8inNW71f8YczFVjXSyNiwtUyzJ+V3uAQ6KkAYD6EHjsReoBrY7PZ9NPe45q/Jl7HTp1R82A/jYyJUHADH6NLQw1HTwUA8yH02InQA9gnv6BQa35O0TcbDij7TJ46RdbX0B5hquvrYXRpqKHoqQBgPoQeOxF6gIpx+my+Yrcc1Iofk2Wz2XTTDY01sEuwvNxdjC4NNQw9FQDMh9BjJ0IPULHSM8/q6x8StPG3I/J0d9bgLiGKaRskF2er0aWhhqCnAoD5EHrsROgBKkfS0SzNWxOvXYnpquvrrmE9w9W+eT1ZWewAlYyeCgDmQ+ixE6EHqFy/JaZp7qp4HTqerdCGPhoZE6GmTfyMLgsmRk8FAPMh9NiJ0ANUvsJCmzbtOqIFPyToZNY5tQr31/CYCAXW9TK6NJgQPRUAzIfQYydCD1B1cvMK9N22ZC3dfFBncwvUPbqRhnQPVW1vN6NLg4nQUwHAfAg9diL0AFUv63Suvt1wQKt/TpGzk1V9OzRWv45N5O7qbHRpMAF6KgCYD6HHToQewDhHT57WV2sTtC3umGp5uWpIt1B1b9VQTlZWesO1o6cCgPkQeuxE6AGMF5+SoS9X79f+Qxlq6O+p4b3C1Tqiriys9IZrQE8FAPMh9NiJ0AM4BpvNpp9/P6F5a+J1NP20rm9cW6N6Ryi0YS2jS0M1Q08FAPMh9NiJ0AM4lvyCQq375bAWrU9U5uk8dWheT0N7hqtebQ+jS0M1QU8FAPMh9NiJ0AM4pjPn8rVsS5KW/5ikggKbercN0uCuIfL2cDG6NDg4eioAmA+hx06EHsCxncw6p0XrE7RuZ6rcXZ01qHOwbmoXJBdnJ6NLg4OipwKA+RB67EToAaqHQ8ezNX9NvHbGp8m/lptu6xGmTpENZGWxA1yEngoA5kPosROhB6he9hxI19zV8Tp4NEtN6ntrZEyEWoTUMbosOBB6KgCYD6HHToQeoPoptNm0dfdRfbU2QWmZZxUVVkcje0UoqN6lmyFqDnoqAJgPocdOhB6g+srLL9D3P6Vo8cYDOpObr64tG+q27mHy83EzujQYiJ4KAOZD6LEToQeo/rLP5GnxxgNatf2QrBaL+nRorP4dg+Xh5mx0aTAAPRUAzIfQYydCD2Aex0+d0YIfErRl91H5eLrolq6h6tm6kZydrEaXhipETwUA8yH02InQA5hPYmqm5q7ar73Jp1Tfz0PDe4Wr7fUBsrDSW41ATwUA8yH02InQA5iTzWbTL/Fpmrd6v1LTTisi0FcjYyIUEeRrdGmoZPRUADAfQo+dCD2AuRUUFmr9zlQtXJeojJxc3dA0QMN7hqt+HU+jS0MloacCgPkQeuxE6AFqhrO5+VqxNVmxW5KUX1CoXq0DNbhbiGp5uhpdGioYPRUAzIfQYydCD1CzZGSf06INB/TDjsNydbFqQKdg3dy+sdxcnIwuDRWEngoA5kPosROhB6iZDp/I0fw18dqx/4T8fNw0pHuoukY1lNXKYgfVHT0VAMyH0GMnQg9Qs+1NOqm5q+OVmJqpoAAvjYiJUFRoHVZ6q8boqQBgPoQeOxF6ANhsNv0Yd0xfrY3X8VNn1SLETyNjItSkvo/RpeEa0FMBwHwIPXYi9AAokpdfqDU/p+ibDYk6fTZfnSIbaGiPMPn7uhtdGsqBngoA5kPosROhB8DFTp/N05JNB/XdtkOSpJvbBWlg52B5ursYXBmuBj0VAMyH0GMnQg+AS0nLOKsFPyRo864j8vJw0eAuIYppGyhnJ6vRpeEy6KkAYD6EHjsRegBcycEjWZq7er/2HDypgNruGtYzXO2b1WOxAwdFTwUA8yH02InQA+Bq2Gw2/ZaYrnmr9+vQ8RyFNqylUb0jdH3j2kaXhovQUwHAfAg9diL0ACiPwkKbNvyWqq9/SNCp7Fy1jqirETHhaujvZXRp+AM9FQDMh9BjJ0IPgGtxLq9A3/2YrKWbDyo3r1A9WjfSrV1D5OvtZnRpNR49FQDMh9BjJ0IPAHtkns7Vt+sPaM2OFDk7WdW/YxP17dBEbq5ORpdWY9FTAcB8CD12IvQAqAhH0k/rq7Xx+mnvcfl6uWpI91B1i24oJysrvVU1eioAmA+hx06EHgAVaf+hDH25+nfFp2SqUV0vDe8Vrlbh/qz0VoXoqQBgPoQeOxF6AFQ0m82m7fuOa/6aeB09eUbNmtTWiJgIhTasZXRpNQI9FQDMh9BjJ0IPgMqSX1CotTsOa9H6RGWfyVPHFvU1rEeY6tb2MLo0U6OnAoD5EHrsROgBUNnOnMvX0s0HteLHZNlsNt14Q5AGdg6Rt4eL0aWZEj0VAMyH0GMnQg+AqpKeeVYL1yVqw6+p8nBz1qAuIbrxhkC5OLPSW0WipwKA+RB67EToAVDVko9la96a/fotIV3+tdw1rGeYOrSoLyuLHVQIeioAmA+hx06EHgBG2XUgXfNW7VfSsWwFN/DRyJgINQ/2M7qsao+eCgDmQ+ixE6EHgJEKbTZt3nVEC35IUHrmOUWH+2tEr3AFBly6sePy6KkAYD6EHjsRegA4grz8Aq3cdkiLNx3U2dx8dY9uqFu7hcnPx83o0qodeioAmA+hx06EHgCOJPtMnr7dcECrth+Sk5NFfds3Ub+OTeTh5mx0adUGPRUAzIfQYydCDwBHdOzkaS34IUFb9xxTLU8X3dotVN1bNZKzk9Xo0hwePRUAzIfQYydCDwBHFn84Q/NW7de+QxlqUMdTw3uFq811dWVhpbdLoqcCgPkQeuxE6AHg6Gw2m3bsP6H5a+KVmnZa1wX5amRMhMIDfY0uzSHRUwHAfAg9diL0AKguCgoLte6XVC1cn6jMnFy1a1ZPw3uGqZ6fp9GlORR6KgCYD6HHToQeANXNmXP5Wr41Scu2JqmgwKaYNoEa3DVEPp6uRpfmEOipAGA+Vwo9hj/xunjxYg0cOFDR0dHq37+/Fi5ceNnjCwsL9Z///Ec33nijoqOjNXjwYC1ZsqTEMfn5+XrjjTfUs2dPtWrVSnfccYd27txZiZ8CAByHh5uzhnQP0z/+3FldWzbU99sP6an3N2np5oPKzSswujwAAKqcoaEnNjZWjz/+uLp27ap33nlHHTp00OTJk7Vs2bJLnvP3v/9d7777rkaPHq33339frVq10mOPPaa1a9cWH/PSSy/p448/1r333qvXX39dTk5Ouuuuu5ScnFwVHwsAHEJtbzfd1b+Zpt3TUdcH1db8NfH66webteHXVBVykR8AUIMYenvbzTffrKioKL3++uvF2yZOnKi9e/cqNja21PFJSUnq27evpk2bphEjRhRvHz16tJo1a6apU6fq0KFD6tOnj55++mndfvvtkqTc3Fz17dtXPXr00PPPP1+uGrm9DYBZxB08qS9X79fBI1lqXM9bI2MiFBlax+iyqhw9FQDMx2Fvb0tOTlZSUpL69OlTYnvfvn2VkJBQ5lWZlStXyt3dXUOGDCmx/bPPPtPUqVMlSZs3b1ZBQYH69u1bvN/V1VW9evXSDz/8UPEfBACqiWbBfnp6bDtNuKWFzpzL1/Qvd2j6lzuUdJQAAAAwN8NCT0JCgiQpNDS0xPbg4GBJUmJiYqlz9u7dq9DQUG3cuFG33HKLWrRooT59+mjp0qUlXtfX11d16pT838vg4GAdPnxYZ8+ereiPAgDVhtViUacWDfTSvZ00qneEDqRm6vmZP+qjxbuVnkl/BACYk7NRb5yVdf5/Fr29S16G8vLykiRlZ2eXOic9PV2pqan661//qkceeURBQUGaN2+eJk2apDp16qhTp07Kzs4u9ZoXvm5OTo7c3d0r+uMAQLXi4mxV3w5N1C26oZZsPKiVPyVra9wx9WnfWP07BsvT3bBvDwAAVDjDvqsVPUp08dTwou1Wa+mLUHl5eUpPT9d7772nmJgYSVLnzp2VkJCgt99+W506ddKlHlG61PtdyeXuDaxKAQE+RpcAwIQCJD04qo6G39xUn8Xu0ZJNB7VuZ6r+dHNT9escIhdnwxf5rBT0VACoWQwLPT4+57/hXHxFJycnp8T+C3l5ecnJyUldu3Yt3maxWNSlSxfNnz9f0vkrR0WvUdbrlnUV6HJYyABATWCVNKbP9eoR3UBzV+3Xfxf+qoVr92t4z3Dd0DSg3P9h5MjoqQBgPg67kEHRszxJSUklth88eLDE/gsFBwersLBQ+fn5Jbbn5eUVf0MOCwvTqVOnlJGRUep1g4KC5OrKcD4AuJSQBrX0xO1tNHFEtFycrHp34W/6+2c/6fdDp4wuDQCAa2ZY6AkODlZQUFCpmTwrVqxQSEiIGjVqVOqc7t27y2azlVjOOj8/X+vWrdMNN9wgSerSpYskafny5cXH5Obmau3atcX7AACXZrFYFB1eV8+Na6+7+jfTiYyzevmz7Xp7wa9KTSt9JR0AAEdn6JOqDz74oKZMmSJfX1/16tVLq1atUmxsbPHcnvT0dCUlJSkiIkLe3t7q3LmzevbsqRdffFGnT59WSEiI5syZo5SUFE2fPl2SFBgYqNtuu634mODgYM2cOVMZGRkaP368kR8XAKoVJ6tVPVo1Usfm9bX8xyTFbknSjt9PqGebRrq1a6hqeXHlHABQPRg6nFSSvvjiC82YMUOpqalq3LixJkyYUDyHZ8GCBZoyZYpmzZqljh07SpLOnj2rN998U4sXL1ZGRoZatGihRx99VB06dCh+zdzcXP3rX//S4sWLdfr0aUVGRurJJ59Uq1atyl0fz/QAwHkZObn6ZkOi1v58WC4uVg3o2ER9OjSRm4uT0aWVCz0VAMznSs/0GB56HB2hBwBKSk3L0fw18fr59xOq7e2qId3D1K1lQ1mt1WOxA3oqAJgPocdOhB4AKNu+5FOat3q/4g9nKjDASyN6RahlWB2HX+mNngoA5kPosROhBwAuzWaz6ae9xzV/TbyOnTqj5sF+GhkToeAGjjsHh54KAOZD6LEToQcAriy/oFCrf07RtxsOKPtMnjpH1tdtPcJU19fD6NJKoacCgPkQeuxE6AGAq3f6bL6Wbj6o77Yly2aTbmoXpIGdg+Xl7mJ0acXoqQBgPoQeOxF6AKD80jPP6usfErTxtyPydHfW4C4himkbJBdnw8bDFaOnAoD5EHrsROgBgGuXdDRL81bv164DJ1XX113DeoarffN6shq42AE9FQDMh9BjJ0IPANjvt8Q0zV0Vr0PHsxXa0EcjYyLUtImfIbXQUwHAfAg9diL0AEDFKCy0adOuI1rwQ4JOZp1T64i6GtYrXIF1vaq0DnoqAJgPocdOhB4AqFi5eQX6bluylm4+qLO5BerRqpGGdAuVr7dblbw/PRUAzIfQYydCDwBUjszTuVq84YBW/5wiZyer+nZorH4dm8jd1blS35eeCgDmQ+ixE6EHACrX0ZOn9dWaeG3be1y1vFw1pFuourdqKCdr5az0Rk8FAPMh9NiJ0AMAVSM+JUNfrt6v/Ycy1NDfU8N7hat1RF1ZKnilN3oqAJgPocdOhB4AqDo2m03b953Q/LXxOpp+Wtc3rq1RvSMU2rBWhb0HPRUAzIfQYydCDwBUvfyCQq375bAWrU9U5uk8dWheT0N7hqtebQ+7X5ueCgDmQ+ixE6EHAIxz5ly+YrckacXWJBUU2tS7bZAGdw2Rt4fLNb8mPRUAzIfQYydCDwAY72TWOS1cl6D1v6bK3dVZg7oE66YbguTi7FTu16KnAoD5EHrsROgBAMdx6Hi25q+J1874NPnXctPQHuHqGFlf1nIsdkBPBQDzIfTYidADAI5nz4F0zV0dr4NHs9SkvrdGxkSoRUidqzqXngoA5kPosROhBwAcU6HNpi27j2rB2nilZZ5TVFgdjewVoaB6l/6mJ9FTAcCMCD12IvQAgGPLyy/Q9z+laPHGAzqTm6+uLRvqtu5h8vNxK/N4eioAmA+hx06EHgCoHrLP5GnxxgNatf2QrBaL+nRorP4dg+Xh5lziOHoqAJgPocdOhB4AqF6OnzqjBT8kaMvuo/LxdNEtXUPVs3UjOTtZJdFTAcCMCD12IvQAQPWUmJqpuav2a2/yKdX381B0uL+27zuu9MxzqlPLTUN7hqtzZAOjywQAVABCj50IPQBQfdlsNv0Sn6ZPYvcoIyevxD5XZ6vG9m9G8AEAE7hS6LFWYS0AAFQpi8Wi1hF15eRU+ttdbn6hFqyNN6AqAEBVI/QAAEwvPfNcmdvTLrEdAGAuhB4AgOn51yp7+WpJWrQ+UfkFhVVYDQCgqhF6AACmN7RnuFydS37Lc3G2KjywlhatT9TLn/2k1LQcg6oDAFQ2FjK4AhYyAABz2LTriBasjS+1etuPccc0a1mc8vILNSImQr3bBspisRhdLgCgHFi9zU6EHgAwl7J66smsc5q5dI9+S0xXZGgdjRvQXH4+l74lDgDgWFi9DQCAK/DzcdOkka30f32u1++HTumZj7Zo656jRpcFAKgghB4AAHR+eeuYtkF6/u4Oql/HU+8t2qX3v9mlnLN5Vz4ZAODQCD0AAFygfh1PTRndVrd1D9W2uGN65qOt2pWYbnRZAAA7EHoAALiIk9WqwV1D9bcxN8jd1UnTv9yh2Sv26VxegdGlAQCuwTUtZGCz2XTo0CE1btxYkpSYmKi5c+fK2dlZQ4cOVWhoaIUXahQWMgAAcylvT83NK9D8tfFaue2QGtTx1L2DWyi0Ya1KrBAAUF4VvnrbkSNHdM8998jV1VVff/21Tpw4oQEDBigzM1OS5OHhodmzZ6tFixb2Ve4gCD0AYC7X2lN3H0jXR0v2KCM7V4O7hmhg52A5O3HDBAA4ggpfve21115Tamqqbr/9dknS3LlzlZmZqTfeeEPff/+9GjZsqH//+9/XXjEAAA6oRUgdvXBPB3VsUY+BpgBQzZQ79GzYsEFjx47VyJEjJUmrVq1Sw4YN1a9fPwUGBmrkyJHavn17hRcKAIDRPN1ddO/gSN0/JErHTp7R8zN/1Pc/HRIj7wDAsZU79GRlZSkoKEiSlJaWpl27dql79+7F+z08PJSfn19xFQIA4GDaN6unafd01PVNamv2d/v02txfdDLrnNFlAQAuodyhp1GjRtq3b58kacmSJZKkmJiY4v3r1q0rDkUAAJiVn4+bJo1opf/r27R4oOmW3Qw0BQBH5FzeEwYNGqR3331XBw8e1JYtW9SwYUN1795dSUlJ+vvf/661a9fqqaeeqoxaAQBwKBaLRTFtAtUi2E8fLN6t97/ZpZ9/P67RfZrK28PF6PIAAH8od+h56KGH5OTkpMWLF6tt27Z68skn5ezsrOzsbG3btk333Xefxo4dWxm1AgDgkIoGmi7ddFDfbDigfcmndM/AFooMrWN0aQAAXeOcnrLYbDbl5+fLxcVc/7PFktUAYC6V3VMPHMnUB9/uVmraad3YNkjDY8Ll5uJUae8HAKiEOT1Fzpw5Iw8PD0nSyZMntXTpUjk5Oalfv36qXbv2NRXriAg9AGAuVdFTGWgKAFWrwkNPZmamJk2apMzMTM2bN0/Z2dm65ZZblJqaKpvNpoCAAM2ZM0eNGze2u3hHQOgBAHOpyp564UDTQV2CNahLCANNAaASVPhw0jfeeENbtmwpXqZ6/vz5Onz4sJ544gnNmjVLVqtVb7zxxjUXDACAWVw40PSbDQcYaAoABil36Fm1apVGjx6tv/zlL5KklStXyt/fX+PGjVOHDh105513auPGjRVeKAAA1VHRQNMHLhpoWshAUwCoMuUOPWlpabruuusknR9UumPHDnXt2rV4v5+fn86cOVNxFQIAYALtmtXTC+M7qmkTP83+bp9e/3IHA00BoIqUO/TUr19fycnJks5f5SkoKFCvXr2K92/fvl0NGzassAIBADCL2t5umjgi+vxA05QMBpoCQBUp95yemJgYffLJJ8rOztaSJUvk6+ur3r176+jRo/rggw+0aNEiPfDAA5VRKwAA1R4DTQGg6pU79DzxxBM6c+aM5s+fr/r16+u5556Tu7u79u3bp9mzZ+uWW27RhAkTKqNWAABMo6yBpuMGNldUqL/RpQGA6VTYcNLc3FxlZGQoICCgIl7OYbBkNQCYiyP21AsHmvZuG6gRMREMNAWAcqi04aSnTp3Sxo0blZKSIhcXFzVs2FBdu3aVt/el36w6IvQAgLk4ak/NzSvQV2sT9N22ZNWv46kJDDQFgKtWKaFnzpw5evXVV3X27FldeLqbm5uefPJJ3XnnnddWrQMi9ACAuTh6T91zIF0fLd2jU1kMNAWAq1XhoWflypV66KGH1KJFC40fP15hYWGy2WxKSEjQzJkztWvXLr377ruKiYmxu3hHQOgBAHOpDj319Nk8zf5unzbtOqrQhj4aP6iFGvp7GV0WADisCg89o0aNUl5enr744gu5urqW2JeXl6dRo0bJw8NDs2fPvraKHQyhBwDMpTr11G1xx/TJsjjl5RdqREyEYtoGymqxGF0WADicK4Wecl8vj4uL06233loq8EiSi4uLbr31Vu3Zs6e8LwsAAC7CQFMAqBjlDj2urq46c+bMJffn5OTIyYkVZwAAqAgXDzR9+sMt2rz7iNFlAUC1Uu7Q0759e82ePVvHjh0rte/o0aOaM2eObrjhhgopDgAA/G+g6fN3d1BDf0/995vdem/Rb8o+k2d0aQBQLZT7mZ59+/Zp1KhRslqtGjJkiEJCQiRJCQkJ+uabb1RQUKDPP/9czZs3r4x6qxzP9ACAuVT3nlpQWKilm5P0zfpE+Xi6aNyA5ooKY6ApgJqtUpas3rlzp1588UXt3LmzxPaoqChNnTpVrVu3LnehjorQAwDmYpaeevBIlj5YvFuHT+Qw0BRAjVdpw0klKS0tTSkpKbLZbAoMDFTdunW1efNm7du3T2PGjLnWl3UohB4AMBcz9VQGmgLAeZUaesry7LPPau7cuaZZwY3QAwDmYsaeykBTADVdhS9ZDQAAHEvzkDqaNq6DOraop282HNDfP/1JqWk5RpcFAA6D0AMAgAl4urvo3sGRemBIlI6fOqPnZv6olduSVVixN3QAQLXkbHQBAACg4rRrVk8RQb6auTROc1b+rh37T2jcgOaqU8vd6NIAwDBc6QEAwGSKBpqO6dtU+1My9MxHWxloCqBGu+KVnsOHD5frBXNyuIcYAACjWSwW9WoTqOYhfvrw29367ze7teP3Exrdp6m8PVyMLg8AqtQVQ0/v3r1lsViu+gVtNlu5jgcAAJWnvp+nnhrdtnig6b7kUww0BVDjXDH0DBkyhBADAEA15mS1anCXEEWH+euDxbv12txfGGgKoEap8Dk9ZsOcHgAwl5reU3PzCrTghwSt+PH8QNN7B7VQWCMGmgKo3pjTAwAAirm6OOlPN16nJ/7UWnn5Bfr7pz9p4boE5RcUGl0aAFQaQg8AADXQ/waa1megKQDTI/QAAFBDnR9o2oKBpgBMj+GkAADUcAw0BWB2XOkBAAAMNAVgaoQeAAAg6X8DTZ8f10EN63rqv9/s1nuLflP2mTyjSwMAuxB6AABACfX9PPXUnW01tEeYftp7XM98tEW/JaQZXRYAXDNCDwAAKMXJatWgLiGaOqadPN1d9NrcX/Tpir06l1tgdGkAUG6EHgAAcEnBDXz07F3t1Kd9Y63enqLnZm5V/OEMo8sCgHIh9AAAgMtycb5goGlBoV7+dDsDTQFUK4aHnsWLF2vgwIGKjo5W//79tXDhwssev2jRIjVt2rTUr2nTphUfk5OTo7///e+KiYlR27Zt9X//93/auXNnJX8SAADMjYGmAKorQ+f0xMbG6vHHH9eYMWPUvXt3rVy5UpMnT5a7u7v69etX5jlxcXEKDg7WK6+8UmJ73bp1i3//zDPPaNWqVXr88ccVHBysmTNnauzYsfrmm2/UuHHjSv1MAACYWdFA0zbX1dWs5Xv13MwfNbxXuG68IUhWi8Xo8gCgTBabzbixyzfffLOioqL0+uuvF2+bOHGi9u7dq9jY2DLPGTdunHx9fUucc6GzZ8+qbdu2euCBB/TQQw9JOn/lp0uXLrr33nuLt12ttLRsFRYaO5k6IMBHx49nGVoDAJgFPbXinMo+p49j47QzPk0tQvwYaArAMFarRf7+3pfeX4W1lJCcnKykpCT16dOnxPa+ffsqISFBycnJZZ4XFxenpk2bXvJ18/LyVFhYKG/v/31oT09Pubm56dSpUxVSOwAAOD/Q9JHh0RrTr6niUzLPDzTddUQG/n8qAJTJsNCTkJAgSQoNDS2xPTg4WJKUmJhY6pxjx44pLS1Nu3fvVr9+/RQZGam+ffuWeA7Ix8dHt912mz755BPt3LlTGRkZmj59unJycjRgwIDK+0AAANRAFotFvVoH6rlx7c8PNP12t95btIuBpgAcimHP9GRlnb+14MIrMpLk5eUlScrOzi51TlxcnCTp0KFDeuKJJ+Tm5qaFCxdq8uTJKigo0LBhwyRJkyZN0oQJEzRixAhJ5xvyiy++qLZt21ba5wEAoCYrGmgauzlJi9Yn6vdDpzRuQHNFhfkbXRoAGBd6ii59Wy566LFou9Va+iJUVFSU3nvvPbVv3744LHXr1k1paWl68803NWzYMKWlpWnkyJFydXXV9OnT5e/vr+XLl+vZZ5+Vp6dnua/2XO7ewKoUEOBjdAkAYBr01Mpz960t1f2Gxnptzna9NvcXDegSorsHRcrdzdC1kwDUcIZ1IB+f899wLr6ik5OTU2L/herUqaOYmJhS23v27KmNGzcqPT1d8+bN05EjR/Tdd98Vr9TWuXNnZWVl6YUXXlC/fv3KDFSXwkIGAGAu9NTK5+vmpKn/11ZfrU3Q0o0H9NOeoxo/uIXCG/kaXRoAk3LYhQyKnuVJSkoqsf3gwYMl9l/o559/1rx580ptP3funJydneXj46PDhw8rICCg1NLU7dq1U3p6utLT0yvqIwAAgEsoHmh6e5vigaZf/8BAUwDGMCz0BAcHKygoSMuWLSuxfcWKFQoJCVGjRo1KnbNjxw5NnTq1+NkeSSosLNTy5cvVtm1bubi4KDQ0VCdOnNCBAwdKnevt7S1fX/6XCQCAqtI82E/TxnVUp8j6+nbjAb306U86fIKBpgCqlqFzehYsWKApU6bozjvvVK9evbRq1Sp9/vnnev311zVgwAClp6crKSlJERER8vb2VkZGhm677TZZrVZNnDhRXl5emjNnjjZt2qTZs2erVatWysrK0q233ipnZ2c9/PDD8vf316pVq/Tpp5/q8ccf17333luuGrm9DQDMhZ5qnG1xxzRr+V6dyytgoCmACnWl29sMDT2S9MUXX2jGjBlKTU1V48aNNWHCBA0ZMkTS/0LRrFmz1LFjR0lSSkqKpk+fri1btig7O1tRUVGaNGmS2rVrV/yaR48e1auvvqp169YpNzdXYWFhGjdunAYOHFju+gg9AGAu9FRjZWSf08w/Bpo2D/bTPQMZaArAfg4fehwdoQcAzIWeajybzaa1vxzWl9/vl5PVotF9rlfHFvVLregKAFfLYRcyAAAANRMDTQFUNUIPAAAwRNFA06E9wrR933E9/dEW/ZqQZnRZAEyI0AMAAAzjZLVqUJcQTR3TTl7uLnp97i/6dPlencstMLo0ACZC6AEAAIYLbuCjZ+9qpz7tG2vNzyl6buZWxR/OMLosACZB6AEAAA6haKDp4ww0BVDBCD0AAMChMNAUQEUj9AAAAIfj6e6s8YNa6IEhUUrLOKvnP/5R321LViGTNgBcA2ejCwAAALiUds3q6bogX82MjdPnK3/Xjt9PMNAUQLlxpQcAADg0X283PTI8WmP6NVXC4Uw9/dFWbdp1RMxXB3C1CD0AAMDhFQ00fX5cewXW9dIH3+7WfxhoCuAqEXoAAEC1Ue+PgabDeobpZwaaArhKhB4AAFCtWK0WDezMQFMAV4/QAwAAqiUGmgK4WoQeAABQbRUNNH3i9jbKZ6ApgEsg9AAAgGqvWbCfnh/XUZ0ZaAqgDIQeAABgCp7uzrpnUAs9eNsFA01/ZKApAIaTAgAAk7mhaT1FBP4x0PT737VjPwNNgZqOKz0AAMB0igaajmWgKQARegAAgElZLBb1ZKApABF6AACAyTHQFAChBwAAmF7RQNOnx7aTNwNNgRqH0AMAAGqMJvV99Mxd7dS3wwUDTVMYaAqYHaEHAADUKC7OThrV+38DTf/+2U9awEBTwNQIPQAAoEYqGmjaJbKBFm88oJdmMdAUMCtCDwAAqLFKDDTNZKApYFYMJwUAADUeA00Bc+NKDwAAgC4x0PQ3BpoCZkDoAQAA+EOpgaaLGWgKmAGhBwAA4CJlDTTdGc9AU6C6IvQAAACU4eKBpm/M+0WzGGgKVEuEHgAAgMu4cKDp2p9T9CwDTYFqh9ADAABwBRcONC1goClQ7RB6AAAArlJZA01TGGgKODxCDwAAQDn8b6Bpy/MDTWf+qBUMNAUcGsNJAQAArsENTQMUEVhLH8fG6Yvvf9cv+09o3IDm8vdloCngaLjSAwAAcI18vd30l+HRuqt/MyUcztQzMxhoCjgiQg8AAIAdLBaLerRqVHKg6cLfGGgKOBBCDwAAQAUoMdD09xMMNAUcCKEHAACggjDQFHBMhB4AAIAKxkBTwLEQegAAACpB0UDTJ+9oo4IC2x8DTeMZaAoYgNADAABQiZo28dO0ezqoS1QDLd54kIGmgAEIPQAAAJXMw81Z9wxkoClgFIaTAgAAVBEGmgLG4EoPAABAFWKgKVD1CD0AAABVrMRA0wAGmgKVjdADAABgkHp+nnrqjgsGmn7IQFOgMhB6AAAADFRioKnnHwNNl8XpbG6+0aUBpkHoAQAAcABN6vvombHt1K9DE63dcVjPzfhR+xloClQIQg8AAICDcHF20sjeEecHmhba9DIDTYEKQegBAABwMAw0BSoWoQcAAMABMdAUqDgMJwUAAHBgNzQNUESQrz5hoClwzbjSAwAA4OB8vVz18LCW5weapmbqmRlbtPG3VAaaAleJ0AMAAFAN/G+gaQcFBnjrw8V79O7C35R1Otfo0gCHR+gBAACoRurV9igeaLrj9xN65qOtDDQFroDQAwAAUM0w0BQoH0IPAABANcVAU+DqEHoAAACqMQaaAldG6AEAADCBooGmXaMaavHGg3px1jYGmgJ/IPQAAACYhIebs8YNbK6HhrZUeua58wNNtyYx0BQ1HsNJAQAATKbt9QEKD/xjoOmq/dqx/4TuGdiCgaaosbjSAwAAYEIXDjRNPJLFQFPUaIQeAAAAk2KgKXAeoQcAAMDkigaaDu8VfsFA0xNGlwVUGUIPAABADWC1WjSgU7CeHttOPp4uemPeTgaaosYg9AAAANQgTer76Omx7dWvIwNNUXMQegAAAGoYF2erRsaUHGj61VoGmsK8CD0AAAA11IUDTZds+mOg6fFso8sCKhyhBwAAoAYrNdD0420MNIXpMJwUAAAADDSFqXGlBwAAAJLKHmi64VcGmqL6I/QAAACg2IUDTYMCvPXRkj1692sGmqJ6I/QAAACglHq1PTT5jrYa0StcO/af0NMfbdUv+xloiuqJ0AMAAIAyWa0W9f9joGktTxe9OX+nPmGgKaohQg8AAAAu68KBpj8w0BTVEKEHAAAAV8RAU1RnhB4AAABcNQaaojoi9AAAAKBcigaaPjy0pU5mnR9oupyBpnBgDCcFAADANWnzx0DTj2Pj9OWq/fpl/wmNG9hcdX09jC4NKIErPQAAALhmtS4aaPrsjK0MNIXDMTz0LF68WAMHDlR0dLT69++vhQsXXvb4RYsWqWnTpqV+TZs2rcRxX3zxhfr376+WLVuqb9++mjVrViV+CgAAgJqLgaZwdIbe3hYbG6vHH39cY8aMUffu3bVy5UpNnjxZ7u7u6tevX5nnxMXFKTg4WK+88kqJ7XXr1i3+/cyZM/XKK6/oz3/+szp27KhNmzbppZdekouLi26//fZK/UwAAAA1VdFA0+Vbk7TghwT9/lGG7u7fTK0i6l75ZKASWWwGXnu8+eabFRUVpddff71428SJE7V3717FxsaWec64cePk6+tb4pwL5eTkqFu3bho7dqwmTpxYvP2xxx7TuXPn9Pbbb5erxrS0bBUWGnt5NiDAR8ePZxlaAwCYBT0VqBpJR7P04eLdOnQ8Rz1bN9Ko3hFyd+VxclQOq9Uif3/vS++vwlpKSE5OVlJSkvr06VNie9++fZWQkKDk5OQyz4uLi1PTpk0v+brr16/X6dOndccdd5TYPn369HIHHgAAAFybMgeaHmKgKYxhWOhJSEiQJIWGhpbYHhwcLElKTEwsdc6xY8eUlpam3bt3q1+/foqMjFTfvn1LPAe0d+9e1a5dW6mpqfrTn/6kqKgo9ezZk2d6AAAAqtiFA00LbTa9PJuBpjCGYaEnK+v8rQXe3iUvQ3l5eUmSsrNLD7mKi4uTJB06dEhPPPGE3n//fbVs2VKTJ0/WV199JUlKT09XXl6e7r//fvXp00cffPCBbrzxRr300ktasGBBZX4kAAAAlKFpEz89P66Durb8Y6DpJ9t0iIGmqEKG3VhZ9CiRxWIpc7vVWjqPRUVF6b333lP79u2Lw1K3bt2UlpamN998U8OGDVNeXp5ycnL06KOPavTo0ZKkzp076/Dhw3rrrbc0dOjQctV5uXsDq1JAgI/RJQCAadBTAWNMHttBPX9L1dvzduiFT7ZpzIDmuqV7uKxWy5VPBuxgWOjx8Tn/DefiKzo5OTkl9l+oTp06iomJKbW9Z8+e2rhxo9LT04uvFPXs2bPEMd27d9fq1auVlZVV5mtfCgsZAIC50FMBY4XX99bzd3fQx7Fx+uibXdqwI4WBprCbwy5kUPQsT1JSUontBw8eLLH/Qj///LPmzZtXavu5c+fk7OwsHx+f4meCcnNLrgufl5cnqfSVJQAAAFStooGmdzPQFFXEsNATHBysoKAgLVu2rMT2FStWKCQkRI0aNSp1zo4dOzR16tTiZ3skqbCwUMuXL1fbtm3l4uKi7t27S5KWLFlS4tzVq1eradOmpZ4hAgAAQNWzWCzq3qqRpo3roMYMNEUlM3Sx9AcffFBTpkyRr6+vevXqpVWrVik2NrZ4Bk96erqSkpIUEREhb29vDR06VJ9++qkeeughTZw4UV5eXpozZ4727dun2bNnS5KaNGmi22+/Xe+//76cnZ3VunVrLVmyRJs3b9a7775r5McFAADARQJqe+jJPwaafr0uQU8z0BSVwNDhpJL0xRdfaMaMGUpNTVXjxo01YcIEDRkyRJK0YMECTZkyRbNmzVLHjh0lSSkpKZo+fbq2bNmi7OxsRUVFadKkSWrXrl3xaxYWFuqDDz7Q3LlzdezYMYWGhuqhhx4qNRPoavBMDwCYCz0VcFzJx7L1wbe7dOh4jnq0aqQ/3chAU1ydKz3TY3jocXSEHgAwF3oq4Njy8gv19boELd+SpLq13TV+UAtdF1Tb6LLg4Bx2IQMAAADgYhcONLXZpH/M3s5AU9iN0AMAAACHw0BTVCRCDwAAABySh5uzxg1oroeHttTJ7HOa9vE2Ld+apEKezkA58WQYAAAAHFqb6wMUHuirT5bF6ctV+/XL/hMMNEW5cKUHAAAADq+Wl6seGspAU1wbQg8AAACqhbIGmr7z9W/KZKAproDQAwAAgGqlaKDpiF7h2hl/Qs98tFU79p8wuiw4MEIPAAAAqh2r1aL+nYL19Nj2quXpon/P36mPY+N0Njff6NLggAg9AAAAqLYa1/PW02Pbq3/HJlr3y2E9O2Orfj90yuiy4GAIPQAAAKjWXJytGhETocl3tmWgKcpE6AEAAIApXN+4tp4f10HdGGiKixB6AAAAYBoebs66u8RA0x+1bAsDTWs6hpMCAADAdC4caDp39fmBpvcMYqBpTcWVHgAAAJhS8UDTAc104CgDTWsyQg8AAABMy2KxqHs0A01rOkIPAAAATK94oGkMA01rIkIPAAAAagSr1aL+HYsGmrr+MdB0j86cY6Cp2RF6AAAAUKOcH2jaTv07NdG6X1L13EwGmpodoQcAAAA1jouzVSN6lRxoOn8NA03NitADAACAGuvCgaZLNx/UCww0NSVCDwAAAGq04oGmw1rqFANNTYnhpAAAAICkNtcFKLwRA03NiCs9AAAAwB8uHGh68GiWnvloq9bvZKBpdUfoAQAAAC5w4UDTJvW8NWMpA02rO0IPAAAAUIa6Fw80/XALA02rKUIPAAAAcAklBpp6uTHQtJoi9AAAAABXwEDT6o3QAwAAAFwFBppWX4QeAAAAoBwYaFr9EHoAAACAcrpwoGnGhQNNC1na2hExnBQAAAC4RhcPNN2x/4TGD2yuurUZaOpIuNIDAAAA2OHCgaZJR7P0zAwGmjoaQg8AAABgpxIDTev7aMbSPXp7wa8MNHUQhB4AAACggtSt7aEnb2+jkTER+jUhjYGmDoLQAwAAAFQgq9Wifh2b6Jmx7eXrzUBTR0DoAQAAACpBUD1vTR3zv4Gmz87Yqn3Jp4wuq0Yi9AAAAACV5MKBppL0z9nbNW/NfuXlM9C0KhF6AAAAgEpWPNA0uqFiNyedH2h6jIGmVYXQAwAAAFSBCweaZuac07RPGGhaVRhOCgAAAFShNtcFKDzQV5/EMtC0qnClBwAAAKhitTzPDzQdN6A5A02rAKEHAAAAMIDFYlG36IYMNK0ChB4AAADAQGUONP2dgaYVidADAAAAGKzUQNOvdmrmUgaaVhRCDwAAAOAgLhxoun4nA00rCqEHAAAAcCAMNK14hB4AAADAARUNNO3eioGm9iL0AAAAAA7Kw81Zd/Vvrr8Mi2agqR0IPQAAAICDa31dXU0b31Etw/w1d/V+vfL5zzpx6ozRZVUbhB4AAACgGihroOm6nYcZaHoVCD0AAABANXHxQNOZS+PODzTNYaDp5RB6AAAAgGqmbm0PPXnHBQNNP9qin38/bnRZDovQAwAAAFRDVkvJgaZvffUrA00vgdADAAAAVGNFA00HdArW+l8ZaFoWQg8AAABQzbk4WzW8V7ieurOtLJY/BpquZqBpEUIPAAAAYBLXBdXWc3f/MdB0CwNNixB6AAAAABMpa6Bp7JaDNXqgKaEHAAAAMKGigabR4XU1b3W8XpmzvcYONCX0AAAAACZVy9NVD94WpXsGNlfSsewaO9CU0AMAAACYmMViUdeW5weaBtfQgaaEHgAAAKAGqFvbQ0/U0IGmhB4AAACghihroOmMGjDQlNADAAAA1DAXDjTdUAMGmhJ6AAAAgBqoJg00JfQAAAAANdj/Bpo2Mu1AU0IPAAAAUMOdH2jaTH8ZHq3M07mmG2hK6AEAAAAgSWodUVfT7ulQYqDpcRMMNCX0AAAAAChW5kDTX6r3QFNCDwAAAIASLhxoGlLfRzNjq/dAU0IPAAAAgDJdPND06Y+26Od91W+gqcVWna9TVYG0tGzDH+AKCPDR8eNZhtYAAGZBTwWAa3PoeLY++Ha3ko9lq1t0Q4U3qqXFGw8oLfOc/Gu5aWjPcHWObGBIbVarRf7+3pfcT+i5AkIPAJgLPRUArl1+QaEWrU/Ukk0HS+1zdbZqbP9mhgSfK4Uebm8DAAAAcFWcnawa1jNctbxcSu3LzS/UgrXxBlR1ZYQeAAAAAOWSmZNX5va0zHNVXMnVIfQAAAAAKBf/Wm7l2m40Qg8AAACAchnaM1yuziWjhKuzVUN7hhtU0eU5G10AAAAAgOqlaLGCBWvjHWL1tish9AAAAAAot86RDRw25FyM29sAAAAAmBqhBwAAAICpEXoAAAAAmJrhoWfx4sUaOHCgoqOj1b9/fy1cuPCyxy9atEhNmzYt9WvatGllHp+dna2YmBj97W9/q4TqAQAAADg6QxcyiI2N1eOPP64xY8aoe/fuWrlypSZPnix3d3f169evzHPi4uIUHBysV155pcT2unXrlnn8yy+/rMOHD1d47QAAAACqB0NDz2uvvab+/fvrr3/9qySpe/fuysjI0JtvvnnJ0LN3715FRkaqdevWV3z9tWvXKjY2Vj4+PhVZNgAAAIBqxLDb25KTk5WUlKQ+ffqU2N63b18lJCQoOTm5zPPi4uLUtGnTK75+RkaGpk6dqieeeEK1atWqkJoBAAAAVD+GhZ6EhARJUmhoaIntwcHBkqTExMRS5xw7dkxpaWnavXu3+vXrp8jISPXt27fM54BeeOEFhYeH609/+lPFFw8AAACg2jDs9rasrCxJkre3d4ntXl5eks4vQHCxuLg4SdKhQ4f0xBNPyM3NTQsXLtTkyZNVUFCgYcOGSZK+++47ff/99/r2229lsVjsqtPf3/vKB1WBgABu0QOAikJPBYCaxbDQY7PZJKlUKCnabrWWvggVFRWl9957T+3bty8OS926dVNaWprefPNNDRs2TOnp6Xr22Wf15JNPKigoyO4609KyVVhos/t17BEQ4KPjx7MMrQEAzIKeCgDmY7VaLnuxwrDb24oWF7j4ik5OTk6J/ReqU6eOYmJiSl0d6tmzp44ePar09HQ999xzCg8P1/Dhw5Wfn6/8/HxJ58NU0e8BAAAA1ByGhZ6iZ3mSkpJKbD948GCJ/Rf6+eefNW/evFLbz507J2dnZ/n4+Gj58uXaunWroqKiFBkZqcjISKWkpOirr75SZGSkDh06VAmfBgAAAICjMuz2tuDgYAUFBWnZsmW6+eabi7evWLFCISEhatSoUalzduzYoX/84x9q2bKlmjVrJkkqLCzU8uXL1bZtW7m4uGj+/Pmlzrv//vsVHR2t+++/X/Xq1au8DwUAAADA4Rg6p+fBBx/UlClT5Ovrq169emnVqlWKjY3V66+/LklKT09XUlKSIiIi5O3traFDh+rTTz/VQw89pIkTJ8rLy0tz5szRvn37NHv2bElSy5YtS72Pq6ur/Pz8ytwHAAAAwNwMu71NkoYOHarnn39e69ev14MPPqitW7fqn//8pwYMGCBJWrNmjUaNGqVdu3ZJknx9ffXpp58qOjpaL7/8siZOnKjTp0/r448/VqtWrYz8KAAAAAAclMVWtFwaynTyZI7hq7f5+3srLa30Et4AgPKjpwKA+VitFvn5eV1yP6EHAAAAgKkZensbAAAAAFQ2Qg8AAAAAUyP0AAAAADA1Qg8AAAAAUyP0AAAAADA1Qg8AAAAAUyP0AAAAADA1Qg8AAAAAUyP0AAAAADA1Qk81sGfPHkVGRurIkSNGlwIA1VJhYaE+//xzDR48WG3atNFNN92kl19+WdnZ2UaXBgCoAs5GF4DLS0hI0J///Gfl5+cbXQoAVFsffvih3njjDd1zzz3q3LmzEhMT9e9//1v79+/XRx99ZHR5AIBKRuhxUPn5+fryyy81ffp0ubi4GF0OAFRbNptNH374oUaNGqXHHntMktSlSxf5+flp0qRJ2rNnj5o3b25wlQCAysTtbQ7qp59+0r/+9S+NGzdOjz/+uNHlAEC1lZOTo1tuuUWDBg0qsT0sLEySlJSUZERZAIAqxJUeBxUeHq6VK1fK399fCxYsMLocAKi2vL29NXXq1FLbV65cKUmKiIio6pIAAFWM0OOg6tata3QJAGBav/zyi/773//qpptuUnh4uNHlAAAqGbe3AQBqlJ9++knjx49XUFCQXnzxRaPLAQBUAUIPAKDGWLp0qe6++241bNhQH3/8sfz8/IwuCQBQBQg9AIAaYebMmXr00UfVunVrzZ49W/Xq1TO6JABAFSH0AABMb968efrHP/6h/v3768MPP5SPj4/RJQEAqhALGQAATC0tLU0vvfSSAgMDdeedd2r37t0l9jdp0kR16tQxqDoAQFUg9AAATG3dunU6c+aMUlJSdOedd5ba/8orr+jWW281oDIAQFWx2Gw2m9FFAAAAAEBl4ZkeAAAAAKZG6AEAAABgaoQeAAAAAKZG6AEAAABgaoQeAAAAAKZG6AEAAABgaszpAQA4lKeeekpff/31ZY+58cYb9e6771ZRRSX17t1bgYGB+vTTTw15fwBA+RF6AAAOacqUKfLz8ytzX8OGDau4GgBAdUboAQA4pJtuuklBQUFGlwEAMAGe6QEAAABgaoQeAEC11bt3b/3tb3/TvHnzdOONN6p169b605/+pM2bN5c6dtu2bbrrrrvUpk0btWnTRmPGjNGPP/5Y6rhffvlF9957r9q3b6+OHTtqwoQJ2rt3b6njvv32Ww0cOFBRUVHq27evPv/880r5jAAA+xF6AAAOKTMzU+np6WX+KigoKD5u48aNmjZtmvr27atHHnlE6enpGj9+vLZu3Vp8zPfff6//+7//U2pqqu6//37df//9Sk1N1V133aXvv/+++Lht27bpzjvvVHx8vO655x7df//92r9/v8aMGaNDhw4VH/frr7/qxRdfVL9+/TRlyhS5urrqueee08qVK6vmDwcAUC4Wm81mM7oIAACKXM3qbQsXLlTz5s3Vu3dvpaSk6J133tFNN90kSUpPT1ffvn0VFhamL7/8Uvn5+brxxhtlsVi0ePFieXt7SzofqgYNGiTpfChycXHRiBEjlJqaqm+//bZ4EYXExEQNGDBAd999t5588kn17t1bhw8f1ldffaXIyEhJUkpKim688UbdcssteuWVVyrrjwYAcI1YyAAA4JBeffVV1a1bt8x9TZo0Kf59WFhYceCRpDp16ujWW2/VZ599prS0NKWkpOjIkSN6/PHHiwOPJNWqVUujR4/W9OnT9dtvv6lJkyb69ddfdffdd5dYNS40NFRfffVViRXjQkJCigOPJAUGBqpOnTo6ceJEhXx2AEDFIvQAABxS27Ztr2r1toiIiFLbgoODZbPZlJKSUnxbWmhoaKnjwsLCJEmHDx+Wk5OTbDabgoODSx3XokWLEl/7+/uXOsbd3V15eXlXrBcAUPV4pgcAUK25uLiU2lb0zE9RkLmUon0uLi4qLCyUJFmtV/7WeDXHAAAcB1d6AADVWlJSUqltBw8elJOTk4KCgoqvviQkJJQ6LjExUZLUoEED1a9fv/jci7366qvy9fXVhAkTKrJ0AEAV4b+qAADV2q+//qodO3YUf33ixAl988036tSpk3x9fRUZGamAgAB9/vnnys7OLj4uOztbc+bMUUBAgKKiolS/fn01a9ZMS5YsKXFccnKyZs2axfM6AFCNcaUHAOCQVq5cWWJBgYvdeuutkiRXV1fde++9Gjt2rNzd3TVnzhwVFhbqySeflHT+1rWnn35aEydO1LBhwzR8+HBJ0vz583Xs2DH9+9//Lr5dbcqUKRo/fryGDRumESNGyGq16rPPPlOtWrV07733VvInBgBUFkIPAMAhvfzyy5fdXxR6WrdurYEDB+rdd99VVlaW2rVrp8cee0zNmjUrPrZv376aMWOG3n33Xb3zzjtydnZWq1at9NJLL6ldu3bFx3Xq1EmffPKJ/v3vf+udd96Rm5ub2rdvryeeeEIBAQGV80EBAJWOOT0AgGqrd+/eCgwM1Keffmp0KQAAB8YzPQAAAABMjdADAAAAwNQIPQAAAABMjWd6AAAAAJgaV3oAAAAAmBqhBwAAAICpEXoAAAAAmBqhBwAAAICpEXoAAAAAmBqhBwAAAICp/T/rrx6CMwhPaAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Prediction on test set:\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
    "\n",
    "# Put model in evaluation mode:\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables :\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Predict:\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "    \n",
    "  # Add batch to GPU\n",
    "\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader:\n",
    "    \n",
    "  b_input_ids, b_input_mask, = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction:\n",
    "\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions:\n",
    "    \n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU:\n",
    "    \n",
    "  logits = logits.detach().cpu().numpy()\n",
    " \n",
    "    \n",
    "    \n",
    "  \n",
    "  # Store predictions and true labels:\n",
    "    \n",
    "  predictions.append(logits)\n",
    "\n",
    "\n",
    "print('    DONE.')"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Predicting labels for 1,267 test sentences...\n",
      "    DONE.\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "accuracy = accuracy_score(test_labels, flat_predictions)\n",
    "print(accuracy)\n",
    "\n",
    "cm = metrics.confusion_matrix(test_labels, flat_predictions)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.6732438831886346\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  }
 ]
}